{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7c203c",
   "metadata": {},
   "source": [
    "## Determine orthologous genes within bacterial genomes\n",
    "### *Using OrthoDB* \n",
    "Date Created: June 26, 2025<br>\n",
    "Date Modified: July 16, 2025<br>\n",
    "Author: Nashira H. Ridgeway<br>\n",
    "\n",
    "This started as an exploratory investigation, but quickly turned into a required manipulation of the OrthoDB data files for the purposes of our experiment. Essentially, OrthoDB stores orthologs in objects called \"Ortho Groups\" or OGs. These groups contain orthologous protein-coding genes found in other species, and can vary greatly in length. The files retrieved from OrthoDB were quite large (hundreds of millions of lines), but luckily we're focused on the essential genes in just *E. coli* and *B. subtilis* for now.\n",
    "\n",
    "The basic workflow of this project involved pulling out genes based on the taxonomy IDs that matched *E. coli* and *B. subtilis*, finding the ortholog groups they were a part of, and isolating those for further annotation. For this preliminary stage in the project, we'll just be pulling out a few species of interest a few branches down on the phylogenetic tree, and comparing the essential genes shared between *E. coli* and *B. subtilis*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3520388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26de5d",
   "metadata": {},
   "source": [
    "### Isolate the OGs of interest\n",
    "Begin with the isolation of *E. coli* and *B. subtilis* genes from the OrthoDB data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c1f8a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary steps: determine the ID for E. coli in the OrthoDB database\n",
    "species = pd.read_csv('odb12v1_species.tab', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff915a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>562</td>\n",
       "      <td>562_0</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>GCF_001286085.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>83333</td>\n",
       "      <td>83333_0</td>\n",
       "      <td>Escherichia coli K-12</td>\n",
       "      <td>GCF_000974885.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1                      2                3   4   5   6\n",
       "234     562    562_0       Escherichia coli  GCF_001286085.1 NaN NaN NaN\n",
       "4522  83333  83333_0  Escherichia coli K-12  GCF_000974885.1 NaN NaN NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species[species[2].str.contains('Escherichia coli')]\n",
    "# Looks like orthoDB IDs are 562_0 and 83333_0 for E. coli and E. coli K12, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4a3edfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1423</td>\n",
       "      <td>1423_0</td>\n",
       "      <td>Bacillus subtilis</td>\n",
       "      <td>GCF_008764245.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1423</td>\n",
       "      <td>1423_1</td>\n",
       "      <td>Bacillus subtilis</td>\n",
       "      <td>GCF_004361725.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1423</td>\n",
       "      <td>1423_2</td>\n",
       "      <td>Bacillus subtilis</td>\n",
       "      <td>GCF_002153395.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>224308</td>\n",
       "      <td>224308_0</td>\n",
       "      <td>Bacillus subtilis subsp. subtilis str. 168</td>\n",
       "      <td>GCF_000009045.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>224308</td>\n",
       "      <td>224308_1</td>\n",
       "      <td>Bacillus subtilis subsp. subtilis str. 168</td>\n",
       "      <td>GCF_000789275.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1                                           2  \\\n",
       "526     1423    1423_0                           Bacillus subtilis   \n",
       "527     1423    1423_1                           Bacillus subtilis   \n",
       "528     1423    1423_2                           Bacillus subtilis   \n",
       "7025  224308  224308_0  Bacillus subtilis subsp. subtilis str. 168   \n",
       "7026  224308  224308_1  Bacillus subtilis subsp. subtilis str. 168   \n",
       "\n",
       "                    3   4   5   6  \n",
       "526   GCF_008764245.1 NaN NaN NaN  \n",
       "527   GCF_004361725.1 NaN NaN NaN  \n",
       "528   GCF_002153395.1 NaN NaN NaN  \n",
       "7025  GCF_000009045.1 NaN NaN NaN  \n",
       "7026  GCF_000789275.1 NaN NaN NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species[species[2].str.contains('Bacillus subtilis')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabddd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use bash to isolate the E. coli genes from the gene_xrefs table (since the files are too large to load into memory)\n",
    "os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"562_0\\\"' > e_coli_genes.tab\") # Isolate E. coli genes\n",
    "os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"83333_0\\\"' > e_coli_k12_genes.tab\") # Isolate E. coli K12 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7469ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv('e_coli_genes.tab', sep='\\t', header=None)\n",
    "genes.columns = ['Ortho_DB_Gene_ID', 'Ortho_DB_Species_ID', 'Protein_Sequence_ID', 'Synonyms', 'UniprotID', 'Emsembl_ID', 'NCBI_Gene_Name', \n",
    "                 'Description', 'Genomic_Coordinates', 'Genomic_DNA_ID', 'Chromosome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeacd58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of the Ortho_DB_Gene_IDs in our tables -> isolate ones that show up in the odb12v1_gene_xrefs.tab file\n",
    "os.system(\"cut -f1 e_coli_genes.tab > e_coli_ids.txt\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' e_coli_ids.txt odb12v1_gene_xrefs.tab > e_coli_xrefs.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3169ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same for E. coli K12 genes\n",
    "os.system(\"cut -f1 e_coli_k12_genes.tab > e_coli_k12_ids.txt\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' e_coli_k12_ids.txt odb12v1_gene_xrefs.tab > e_coli_k12_xrefs.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec71529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of those gene IDs -> disseminate into OG ids \n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' e_coli_ids.txt odb12v1_OG2genes.tab > e_coli_OG2genes.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' e_coli_k12_ids.txt odb12v1_OG2genes.tab > e_coli_k12_OG2genes.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80d619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of those OG ids -> find matches in the antecedent column \n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' e_coli_OG2genes.tab odb12v1_OG_pairs.tab > e_coli_OG_antecedent_pairs.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' e_coli_k12_OG2genes.tab odb12v1_OG_pairs.tab > e_coli_k12_OG_antecedent_pairs.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498caeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same for the descendant column\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' e_coli_OG2genes.tab odb12v1_OG_pairs.tab > e_coli_OG_descendent_pairs.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' e_coli_k12_OG2genes.tab odb12v1_OG_pairs.tab > e_coli_k12_OG_descendent_pairs.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37316b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have our datasets for E. coli and E. coli K12, with antecedent and descendant OGs for their genes -- we need to disseminate the OG information to relevant genomic\n",
    "# information, such as the gene, protein sequence, and species ID\n",
    "# Make a list of the columns we want to translate, then use the OG2genes.tab file to get our gene IDs, then use the xrefs file to get the other IDs to make a dictionary\n",
    "os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' e_coli_OG_antecedent_pairs.tab > OG_IDs_found_list.txt\")\n",
    "os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' e_coli_OG_descendent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' e_coli_k12_OG_antecedent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' e_coli_k12_OG_descendent_pairs.tab >> OG_IDs_found_list.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0862d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same preliminary filtering steps for B. subtilis (all 3 variants in OrthoDB) 1423_0, 1423_1, and 1423_2, as well as 224308_0 and 224308_1\n",
    "# Use bash to isolate the E. coli genes from the gene_xrefs table (since the files are too large to load into memory)\n",
    "#os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"1423_0\\\"' > subtilis_0_genes.tab\") # Isolate B. subtilis 0 genes\n",
    "#os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"1423_1\\\"' > subtilis_1_genes.tab\") # Isolate B. subtilis 1 genes\n",
    "#os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"1423_2\\\"' > subtilis_2_genes.tab\") # Isolate B. subtilis 2 genes\n",
    "os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"224308_0\\\"' > subtilis_168_0_genes.tab\") # Isolate B. subtilis subspecies 168 0 genes\n",
    "os.system(\"cat odb12v1_genes.tab | awk -F'\\t' '$2 == \\\"224308_1\\\"' > subtilis_168_1_genes.tab\") # Isolate B. subtilis subspecies 168 1 genes\n",
    "\n",
    "# Of the Ortho_DB_Gene_IDs in our tables -> isolate ones that show up in the odb12v1_gene_xrefs.tab file\n",
    "#os.system(\"cut -f1 subtilis_0_genes.tab > subtilis_0_ids.txt\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_0_ids.txt odb12v1_gene_xrefs.tab > subtilis_0_xrefs.tab\")\n",
    "#os.system(\"cut -f1 subtilis_1_genes.tab > subtilis_1_ids.txt\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_1_ids.txt odb12v1_gene_xrefs.tab > subtilis_1_xrefs.tab\")\n",
    "#os.system(\"cut -f1 subtilis_2_genes.tab > subtilis_2_ids.txt\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_2_ids.txt odb12v1_gene_xrefs.tab > subtilis_2_xrefs.tab\")\n",
    "os.system(\"cut -f1 subtilis_168_0_genes.tab > subtilis_168_0_ids.txt\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_168_0_ids.txt odb12v1_gene_xrefs.tab > subtilis_168_0_xrefs.tab\")\n",
    "os.system(\"cut -f1 subtilis_168_1_genes.tab > subtilis_168_1_ids.txt\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_168_1_ids.txt odb12v1_gene_xrefs.tab > subtilis_168_1_xrefs.tab\")\n",
    "\n",
    "# Of those gene IDs -> disseminate into OG ids \n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_0_ids.txt odb12v1_OG2genes.tab > subtilis_0_OG2genes.tab\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_1_ids.txt odb12v1_OG2genes.tab > subtilis_1_OG2genes.tab\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_2_ids.txt odb12v1_OG2genes.tab > subtilis_2_OG2genes.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_168_0_ids.txt odb12v1_OG2genes.tab > subtilis_168_0_OG2genes.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_168_1_ids.txt odb12v1_OG2genes.tab > subtilis_168_1_OG2genes.tab\")\n",
    "\n",
    "# Of those OG ids -> find matches in the antecedent column \n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_0_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_0_OG_antecedent_pairs.tab\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_1_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_1_OG_antecedent_pairs.tab\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_2_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_2_OG_antecedent_pairs.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_168_0_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_168_0_OG_antecedent_pairs.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $2 in ids' subtilis_168_1_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_168_1_OG_antecedent_pairs.tab\")\n",
    "\n",
    "# Do the same for the descendant column\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_0_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_0_OG_descendent_pairs.tab\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_1_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_1_OG_descendent_pairs.tab\")\n",
    "#os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_2_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_2_OG_descendent_pairs.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_168_0_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_168_0_OG_descendent_pairs.tab\")\n",
    "os.system(\"awk 'NR==FNR { ids[$1]; next } $1 in ids' subtilis_168_1_OG2genes.tab odb12v1_OG_pairs.tab > subtilis_168_1_OG_descendent_pairs.tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47256476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a list of the columns we want to translate, then use the OG2genes.tab file to get our gene IDs, then use the xrefs file to get the other IDs to make a dictionary\n",
    "#os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_0_OG_antecedent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "#os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_0_OG_descendent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "#os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_1_OG_antecedent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "#os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_1_OG_descendent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "#os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_2_OG_antecedent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "#os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_2_OG_descendent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "\n",
    "os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_168_0_OG_antecedent_pairs.tab >> OG_IDs_found_list.txt\")\n",
    "os.system(\"awk '{print $1 \\\"\\\\n\\\" $2}' subtilis_168_1_OG_antecedent_pairs.tab >> OG_IDs_found_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e860d1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prep OG_IDs_found_list.txt for use in the next step (remove duplicates) ~250K IDs found\n",
    "os.system(\"sort OG_IDs_found_list.txt | uniq > OG_IDs_found_list_unique.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944df086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now of the OG IDs found, we need to trace back to the gene IDs that match them\n",
    "os.system(\"awk 'NR==FNR { og[$1]; next } $1 in og' OG_IDs_found_list_unique.txt odb12v1_OG2genes.tab > relevant_OG_gene_pairs.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf843f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in 1,000,000 lines...\n",
      "Read in 2,000,000 lines...\n",
      "Read in 3,000,000 lines...\n",
      "Read in 4,000,000 lines...\n",
      "Read in 5,000,000 lines...\n",
      "Read in 6,000,000 lines...\n",
      "Read in 7,000,000 lines...\n",
      "Read in 8,000,000 lines...\n",
      "Read in 9,000,000 lines...\n",
      "Read in 10,000,000 lines...\n",
      "Read in 11,000,000 lines...\n",
      "Read in 12,000,000 lines...\n",
      "Read in 13,000,000 lines...\n",
      "Read in 14,000,000 lines...\n",
      "Read in 15,000,000 lines...\n",
      "Read in 16,000,000 lines...\n",
      "Read in 17,000,000 lines...\n",
      "Read in 18,000,000 lines...\n",
      "Read in 19,000,000 lines...\n",
      "Read in 20,000,000 lines...\n",
      "Read in 21,000,000 lines...\n",
      "Read in 22,000,000 lines...\n",
      "Read in 23,000,000 lines...\n",
      "Read in 24,000,000 lines...\n",
      "Read in 25,000,000 lines...\n",
      "Read in 26,000,000 lines...\n",
      "Read in 27,000,000 lines...\n",
      "Read in 28,000,000 lines...\n",
      "Read in 29,000,000 lines...\n",
      "Read in 30,000,000 lines...\n",
      "Read in 31,000,000 lines...\n",
      "Read in 32,000,000 lines...\n",
      "Read in 33,000,000 lines...\n",
      "Read in 34,000,000 lines...\n",
      "Read in 35,000,000 lines...\n",
      "Read in 36,000,000 lines...\n",
      "Read in 37,000,000 lines...\n",
      "Read in 38,000,000 lines...\n",
      "Read in 39,000,000 lines...\n",
      "Read in 40,000,000 lines...\n",
      "Read in 41,000,000 lines...\n",
      "Read in 42,000,000 lines...\n",
      "Read in 43,000,000 lines...\n",
      "Read in 44,000,000 lines...\n",
      "Read in 45,000,000 lines...\n",
      "Read in 46,000,000 lines...\n",
      "Read in 47,000,000 lines...\n",
      "Read in 48,000,000 lines...\n",
      "Read in 49,000,000 lines...\n",
      "Read in 50,000,000 lines...\n",
      "Read in 51,000,000 lines...\n",
      "Read in 52,000,000 lines...\n",
      "Read in 53,000,000 lines...\n",
      "Read in 54,000,000 lines...\n",
      "Read in 55,000,000 lines...\n",
      "Read in 56,000,000 lines...\n",
      "Read in 57,000,000 lines...\n",
      "Read in 58,000,000 lines...\n",
      "Read in 59,000,000 lines...\n",
      "Read in 60,000,000 lines...\n",
      "Read in 61,000,000 lines...\n",
      "Read in 62,000,000 lines...\n",
      "Read in 63,000,000 lines...\n",
      "Read in 64,000,000 lines...\n",
      "Read in 65,000,000 lines...\n",
      "Read in 66,000,000 lines...\n",
      "Read in 67,000,000 lines...\n",
      "Read in 68,000,000 lines...\n",
      "Read in 69,000,000 lines...\n",
      "Read in 70,000,000 lines...\n",
      "Read in 71,000,000 lines...\n",
      "Read in 72,000,000 lines...\n",
      "Read in 73,000,000 lines...\n",
      "Read in 74,000,000 lines...\n",
      "Read in 75,000,000 lines...\n",
      "Read in 76,000,000 lines...\n",
      "Read in 77,000,000 lines...\n",
      "Read in 78,000,000 lines...\n",
      "Read in 79,000,000 lines...\n",
      "Read in 80,000,000 lines...\n",
      "Read in 81,000,000 lines...\n",
      "Read in 82,000,000 lines...\n",
      "Read in 83,000,000 lines...\n",
      "Read in 84,000,000 lines...\n",
      "Read in 85,000,000 lines...\n",
      "Read in 86,000,000 lines...\n",
      "Read in 87,000,000 lines...\n",
      "Read in 88,000,000 lines...\n",
      "Read in 89,000,000 lines...\n",
      "Read in 90,000,000 lines...\n",
      "Read in 91,000,000 lines...\n",
      "Read in 92,000,000 lines...\n",
      "Read in 93,000,000 lines...\n",
      "Read in 94,000,000 lines...\n",
      "Read in 95,000,000 lines...\n",
      "Read in 96,000,000 lines...\n",
      "Read in 97,000,000 lines...\n",
      "Read in 98,000,000 lines...\n",
      "Read in 99,000,000 lines...\n",
      "Read in 100,000,000 lines...\n",
      "Read in 101,000,000 lines...\n",
      "Read in 102,000,000 lines...\n",
      "Read in 103,000,000 lines...\n",
      "Read in 104,000,000 lines...\n",
      "Read in 105,000,000 lines...\n",
      "Read in 106,000,000 lines...\n",
      "Read in 107,000,000 lines...\n",
      "Read in 108,000,000 lines...\n",
      "Read in 109,000,000 lines...\n",
      "Read in 110,000,000 lines...\n",
      "Read in 111,000,000 lines...\n",
      "Read in 112,000,000 lines...\n",
      "Read in 113,000,000 lines...\n",
      "Read in 114,000,000 lines...\n",
      "Read in 115,000,000 lines...\n",
      "Read in 116,000,000 lines...\n",
      "Read in 117,000,000 lines...\n",
      "Read in 118,000,000 lines...\n",
      "Read in 119,000,000 lines...\n",
      "Read in 120,000,000 lines...\n",
      "Read in 121,000,000 lines...\n",
      "Read in 122,000,000 lines...\n",
      "Read in 123,000,000 lines...\n",
      "Read in 124,000,000 lines...\n",
      "Read in 125,000,000 lines...\n",
      "Read in 126,000,000 lines...\n",
      "Read in 127,000,000 lines...\n",
      "Read in 128,000,000 lines...\n",
      "Read in 129,000,000 lines...\n",
      "Read in 130,000,000 lines...\n",
      "Read in 131,000,000 lines...\n",
      "Read in 132,000,000 lines...\n",
      "Read in 133,000,000 lines...\n",
      "Read in 134,000,000 lines...\n",
      "Read in 135,000,000 lines...\n",
      "Read in 136,000,000 lines...\n",
      "Read in 137,000,000 lines...\n",
      "Read in 138,000,000 lines...\n",
      "Read in 139,000,000 lines...\n",
      "Read in 140,000,000 lines...\n",
      "Read in 141,000,000 lines...\n",
      "Read in 142,000,000 lines...\n",
      "Read in 143,000,000 lines...\n",
      "Read in 144,000,000 lines...\n",
      "Read in 145,000,000 lines...\n",
      "Read in 146,000,000 lines...\n",
      "Read in 147,000,000 lines...\n",
      "Read in 148,000,000 lines...\n",
      "Read in 149,000,000 lines...\n",
      "Read in 150,000,000 lines...\n",
      "Read in 151,000,000 lines...\n",
      "Read in 152,000,000 lines...\n",
      "Read in 153,000,000 lines...\n",
      "Read in 154,000,000 lines...\n",
      "Read in 155,000,000 lines...\n",
      "Read in 156,000,000 lines...\n",
      "Read in 157,000,000 lines...\n",
      "Read in 158,000,000 lines...\n",
      "Read in 159,000,000 lines...\n",
      "Read in 160,000,000 lines...\n",
      "Read in 161,000,000 lines...\n",
      "Read in 162,000,000 lines...\n",
      "Processed 1,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 2,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 3,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 4,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 5,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 6,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 7,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 8,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 9,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 10,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 11,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 12,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 13,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 14,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 15,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 16,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 17,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 18,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 19,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 20,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 21,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 22,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 23,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 24,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 25,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 26,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 27,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 28,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 29,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 30,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 31,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 32,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 33,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 34,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 35,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 36,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 37,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 38,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 39,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 40,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 41,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 42,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 43,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 44,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 45,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 46,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 47,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 48,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 49,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 50,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 51,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 52,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 53,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 54,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 55,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 56,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 57,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 58,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 59,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 60,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 61,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 62,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 63,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 64,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 65,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 66,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 67,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 68,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 69,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 70,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 71,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 72,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 73,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 74,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 75,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 76,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 77,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 78,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 79,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 80,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 81,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 82,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 83,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 84,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 85,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 86,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 87,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 88,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 89,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 90,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 91,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 92,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 93,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 94,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n",
      "Processed 95,000,000 lines...\n",
      "Found 0 genes with missing data in the xref_map...\n"
     ]
    }
   ],
   "source": [
    "# Finally, use the gene IDs to isolate the relevant genomic information (hopefully reducing the file size so we can finally import it...)\n",
    "# After a few attempts, I determined the easiest way to work with this was to import the whole thing locally\n",
    "# QUICKER OPTION\n",
    "import csv\n",
    "\n",
    "xref_map = {}\n",
    "\n",
    "with open(\"odb12v1_genes.tab\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for i, row in enumerate(reader, 1):\n",
    "        if len(row) >= 11:\n",
    "            xref_map[row[0]] = row[1:11]\n",
    "        if i % 1000000 == 0:\n",
    "            print(f\"Read in {i:,} lines...\")\n",
    "\n",
    "errs = 0\n",
    "\n",
    "with open(\"relevant_OG_gene_pairs.txt\", newline=\"\") as f_in, open(\"relevant_OG_gene_info_6.txt\", \"w\", newline=\"\") as f_out:\n",
    "\n",
    "    reader = csv.reader(f_in, delimiter=\"\\t\")\n",
    "    writer = csv.writer(f_out, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
    "\n",
    "    for j, row in enumerate(reader, 1):\n",
    "        og, gene = row\n",
    "        extra = xref_map.get(gene, [\"NA\"] * 10)\n",
    "        if \"NA\" in extra:\n",
    "            errs += 1\n",
    "        writer.writerow([og, gene] + extra)\n",
    "        if j % 1000000 == 0:\n",
    "            print(f\"Processed {j:,} lines...\")\n",
    "            print(f\"Found {errs:,} genes with missing data in the xref_map...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d39a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now utilise SQLite to import the relevant genomic information into an accessible database format, saving as xref.db\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('xref.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE TABLE xref (OG_ID TEXT, gene_ID TEXT, tax_ID TEXT, wp_ID TEXT, protein_ID TEXT, synonyms TEXT, uniprot_ID TEXT, ensembl_ID TEXT, NCBI_GID TEXT, description TEXT, genomic_coordinates TEXT, genomic_DNA_ID TEXT, chromosome TEXT)\")\n",
    "\n",
    "with open(\"relevant_og_gene_info_6.txt\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if \":\" in parts[1]:\n",
    "            tax_id = parts[1].split(\":\")[0]  # extract from gene_ID\n",
    "            cur.execute(\"INSERT INTO xref VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "                        (parts[0], parts[1], tax_id, *parts[2:]))\n",
    "        else:\n",
    "            print(\"malformed line:\", line.strip())\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26b7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHORTER RUNTIME VERSION -- LOAD XREF TABLE INTO MEMORY THEN MAP ORTHOLOGS TO GENES\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import sqlite3\n",
    "\n",
    "def extract_taxid(full_id):\n",
    "    \"\"\"Extract the taxonomy ID from a full OrthoDB gene ID.\"\"\"\n",
    "    try:\n",
    "        return full_id.split(':')[0]\n",
    "    except:\n",
    "        print('error with splitting full_id [0]:', full_id)\n",
    "        return full_id\n",
    "\n",
    "def extract_gene_core_id(full_id):\n",
    "    \"\"\"Extract the core gene ID from a full OrthoDB gene ID.\"\"\"\n",
    "    try:\n",
    "        return full_id.split(':')[1]\n",
    "    except:\n",
    "            print('error with splitting ful_id [1]:', full_id)\n",
    "            return full_id\n",
    "\n",
    "def map_orthologs_to_genes_shorter(bacterial_file_name, tax_id, og_to_genes):\n",
    "    ortholog_map = defaultdict(list)\n",
    "    counter = 0\n",
    "    error_counter = []\n",
    "\n",
    "    with open(bacterial_file_name) as f:\n",
    "        for line in f:\n",
    "            non_og, tax_og = line.strip().split('\\t')\n",
    "\n",
    "            tax_gene_ids = [\n",
    "                gene_id for (gene_id, _) in og_to_genes.get(tax_og, [])\n",
    "                if extract_taxid(gene_id) == tax_id\n",
    "            ]\n",
    "            if not tax_gene_ids:\n",
    "                error_counter.append(tax_og)\n",
    "                continue\n",
    "\n",
    "            ortholog_ids = [\n",
    "                (extract_taxid(gid), extract_gene_core_id(gid))\n",
    "                for (gid, _) in og_to_genes.get(non_og, [])\n",
    "                if extract_taxid(gid) != tax_id\n",
    "            ]\n",
    "\n",
    "            for tax_gene_full in tax_gene_ids:\n",
    "                gene_core = extract_gene_core_id(tax_gene_full)\n",
    "                ortholog_map[gene_core].extend(ortholog_ids)\n",
    "\n",
    "            counter += 1\n",
    "            if counter % 10000 == 0:\n",
    "                print(f\"Processed {counter} OG pairs... ({len(ortholog_map)} genes mapped)\")\n",
    "\n",
    "    return ortholog_map, error_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('xref.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Step 1: load xref table into memory\n",
    "print(\"Loading xref table into memory...\")\n",
    "og_to_genes = defaultdict(list)\n",
    "cur.execute(\"SELECT OG_ID, gene_ID, uniprot_ID FROM xref\")\n",
    "for og_id, gene_id, uniprot in cur.fetchall():\n",
    "    og_to_genes[og_id].append((gene_id, uniprot))\n",
    "print(f\"Loaded {len(og_to_genes)} OGs from xref table.\")\n",
    "\n",
    "# Step 2: call the mapping function\n",
    "e_coli_ortholog_map, e_coli_errors = map_orthologs_to_genes_shorter(\"e_coli_OG_antecedent_pairs.tab\", \"562_0\", og_to_genes)\n",
    "\n",
    "# Step 3: save results\n",
    "with open(\"e_coli_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(e_coli_ortholog_map, f)\n",
    "\n",
    "print(f\"Finished mapping E. coli orthologs to genes. Found {len(e_coli_ortholog_map)} unique E. coli genes with orthologs, found {len(e_coli_errors)} errors.\")\n",
    "\n",
    "# Repeat for other species\n",
    "\n",
    "e_coli_k12_ortholog_map, e_coli_k12_errors = map_orthologs_to_genes_shorter(\"e_coli_k12_OG_antecedent_pairs.tab\", \"83333_0\", og_to_genes)\n",
    "with open(\"e_coli_k12_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(e_coli_k12_ortholog_map, f)\n",
    "\n",
    "print(f\"Finished mapping E. coli K12 orthologs to genes. Found {len(e_coli_k12_ortholog_map)} unique E. coli K12 genes with orthologs, found {len(e_coli_k12_errors)} errors.\" )\n",
    "\n",
    "b_subtilis_0_ortholog_map, b_subtilis_0_errors = map_orthologs_to_genes_shorter(\"subtilis_0_OG_antecedent_pairs.tab\", \"1423_0\", og_to_genes)\n",
    "with open(\"b_subtilis_0_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(b_subtilis_0_ortholog_map, f)\n",
    "\n",
    "print(f\"Finished mapping B. subtilis 0 orthologs to genes. Found {len(b_subtilis_0_ortholog_map)} unique B. subtilis 0 genes with orthologs, found {len(b_subtilis_0_errors)} errors.\")\n",
    "\n",
    "b_subtilis_1_ortholog_map, b_subtilis_1_errors = map_orthologs_to_genes_shorter(\"subtilis_1_OG_antecedent_pairs.tab\", \"1423_1\", og_to_genes)\n",
    "with open(\"b_subtilis_1_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(b_subtilis_1_ortholog_map, f) \n",
    "\n",
    "print(f\"Finished mapping B. subtilis 1 orthologs to genes. Found {len(b_subtilis_1_ortholog_map)} unique B. subtilis 1 genes with orthologs, found {len(b_subtilis_1_errors)} errors.\")\n",
    "\n",
    "b_subtilis_2_ortholog_map, b_subtilis_2_errors = map_orthologs_to_genes_shorter(\"subtilis_2_OG_antecedent_pairs.tab\", \"1423_2\", og_to_genes)\n",
    "with open(\"b_subtilis_2_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(b_subtilis_2_ortholog_map, f)\n",
    "\n",
    "print(f\"Finished mapping B. subtilis 2 orthologs to genes. Found {len(b_subtilis_2_ortholog_map)} unique B. subtilis 2 genes with orthologs, found {len(b_subtilis_2_errors)} errors.\")  \n",
    "\n",
    "b_subtilis_168_0_ortholog_map, b_subtilis_168_0_errors = map_orthologs_to_genes_shorter(\"subtilis_168_0_OG_antecedent_pairs.tab\", \"224308_0\", og_to_genes)\n",
    "with open(\"b_subtilis_168_0_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(b_subtilis_168_0_ortholog_map, f)\n",
    "\n",
    "print(f\"Finished mapping B. subtilis 168_0 orthologs to genes. Found {len(b_subtilis_168_0_ortholog_map)} unique B. subtilis 168_0 genes with orthologs, found {len(b_subtilis_168_0_errors)} errors.\")  \n",
    "\n",
    "b_subtilis_168_1_ortholog_map, b_subtilis_168_1_errors = map_orthologs_to_genes_shorter(\"subtilis_168_1_OG_antecedent_pairs.tab\", \"224308_1\", og_to_genes)\n",
    "with open(\"b_subtilis_168_1_ortholog_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(b_subtilis_168_1_ortholog_map, f)\n",
    "\n",
    "print(f\"Finished mapping B. subtilis 168_1 orthologs to genes. Found {len(b_subtilis_168_1_ortholog_map)} unique B. subtilis 168_1 genes with orthologs, found {len(b_subtilis_168_1_errors)} errors.\")  \n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf2e05",
   "metadata": {},
   "source": [
    "#  Created .gpickle DB files for *E. coli* and *B. subtilis*\n",
    "Now we have .gpickle files with the databases containing the OGs and genes associated with our organisms of interest. We may go on and begin isolating the essential genes from here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14259a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>208964</td>\n",
       "      <td>208964_0</td>\n",
       "      <td>Pseudomonas aeruginosa PAO1</td>\n",
       "      <td>GCF_000006765.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1                            2                3   4   5  \\\n",
       "6761  208964  208964_0  Pseudomonas aeruginosa PAO1  GCF_000006765.1 NaN NaN   \n",
       "\n",
       "       6  \n",
       "6761 NaN  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OrthoDB Python API",
   "language": "python",
   "name": "odb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
